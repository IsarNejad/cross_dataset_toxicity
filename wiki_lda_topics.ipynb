{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wiki_lda_topics.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWptNTgWoJKb",
        "colab_type": "text"
      },
      "source": [
        "This notebook trains a LDA topic model on the Wikipedia dataset annotated for personal attack. Then uses this model to find the distribution of topics in two other datasets Waseem and Founta. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVN3y76qok-1",
        "colab_type": "text"
      },
      "source": [
        "#Installations and preparing the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fo8tVoBBe3cf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "!pip install --upgrade gensim  #gensim-3.8.3\n",
        "!pip install pyLDAvis  #Successfully installed funcy-1.14 pyLDAvis-2.1.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GO80sqCtOy2i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tweet-preprocessor  #tweet-preprocessor-0.6.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5IUbaJcffI_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "import gensim.corpora as corpora\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "from gensim import similarities\n",
        "\n",
        "import numpy as np\n",
        "nltk.download('stopwords') \n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import os.path\n",
        "import re\n",
        "import glob\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNirUzB0fhmL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd \"YOUR-Current-Directory\" #/content/drive/My Drive/Colab_Notebooks/toxicity/wiki-lda-share/' "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JafvH9BXhfSt",
        "colab_type": "text"
      },
      "source": [
        "#Reading and Preparing the Wikipedia Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUj7Uc7YflI-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "comments = pd.read_csv('Wiki/toxicity_annotated_comments.tsv', sep = '\\t', index_col = 0)\n",
        "annotations = pd.read_csv('Wiki/toxicity_annotations.tsv',  sep = '\\t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nr3t754Yfx2J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# join labels and comments\n",
        "comments['toxicity'] = annotations.groupby('rev_id')['toxicity'].mean() > 0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JT_FkRC-f0wv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove newline and tab tokens\n",
        "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"NEWLINE_TOKEN\", \" \"))\n",
        "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"TAB_TOKEN\", \" \"))\n",
        "comments['comment'] = comments['comment'].apply(lambda x:re.sub(r'[^A-Za-z0-9 ]+', ' ', x).lower())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1cjuGBUgifo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "outputId": "ba463140-cd96-412a-d17f-688a859e0259"
      },
      "source": [
        "comments.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>year</th>\n",
              "      <th>logged_in</th>\n",
              "      <th>ns</th>\n",
              "      <th>sample</th>\n",
              "      <th>split</th>\n",
              "      <th>toxicity</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rev_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2232.0</th>\n",
              "      <td>this   one can make an analogy in mathematical...</td>\n",
              "      <td>2002</td>\n",
              "      <td>True</td>\n",
              "      <td>article</td>\n",
              "      <td>random</td>\n",
              "      <td>train</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4216.0</th>\n",
              "      <td>clarification for you   and zundark s righ...</td>\n",
              "      <td>2002</td>\n",
              "      <td>True</td>\n",
              "      <td>user</td>\n",
              "      <td>random</td>\n",
              "      <td>train</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8953.0</th>\n",
              "      <td>elected or electoral  jhk</td>\n",
              "      <td>2002</td>\n",
              "      <td>False</td>\n",
              "      <td>article</td>\n",
              "      <td>random</td>\n",
              "      <td>test</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26547.0</th>\n",
              "      <td>this is such a fun entry    devotchka  i once...</td>\n",
              "      <td>2002</td>\n",
              "      <td>True</td>\n",
              "      <td>article</td>\n",
              "      <td>random</td>\n",
              "      <td>train</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28959.0</th>\n",
              "      <td>please relate the ozone hole to increases in c...</td>\n",
              "      <td>2002</td>\n",
              "      <td>True</td>\n",
              "      <td>article</td>\n",
              "      <td>random</td>\n",
              "      <td>test</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   comment  ...  toxicity\n",
              "rev_id                                                      ...          \n",
              "2232.0   this   one can make an analogy in mathematical...  ...     False\n",
              "4216.0       clarification for you   and zundark s righ...  ...     False\n",
              "8953.0                           elected or electoral  jhk  ...     False\n",
              "26547.0   this is such a fun entry    devotchka  i once...  ...     False\n",
              "28959.0  please relate the ozone hole to increases in c...  ...     False\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cBJLdFQgZNX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "26e47308-dcd3-42d3-9cb3-7be3a121e9cf"
      },
      "source": [
        "comments.groupby('toxicity').count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>year</th>\n",
              "      <th>logged_in</th>\n",
              "      <th>ns</th>\n",
              "      <th>sample</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>toxicity</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>False</th>\n",
              "      <td>144324</td>\n",
              "      <td>144324</td>\n",
              "      <td>144324</td>\n",
              "      <td>144324</td>\n",
              "      <td>144324</td>\n",
              "      <td>144324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>True</th>\n",
              "      <td>15362</td>\n",
              "      <td>15362</td>\n",
              "      <td>15362</td>\n",
              "      <td>15362</td>\n",
              "      <td>15362</td>\n",
              "      <td>15362</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          comment    year  logged_in      ns  sample   split\n",
              "toxicity                                                    \n",
              "False      144324  144324     144324  144324  144324  144324\n",
              "True        15362   15362      15362   15362   15362   15362"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "382-HNv7pNGQ",
        "colab_type": "text"
      },
      "source": [
        "#Training wiki-lda"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIkNXBJSnKD3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lemmatize_stemming(text):\n",
        "    stemmer = SnowballStemmer(\"english\")\n",
        "    \n",
        "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))  \n",
        "\n",
        "def preprocess(text):\n",
        "    result = []\n",
        "    for token in gensim.utils.simple_preprocess(text, deacc=True):  # deacc=True removes punctuations\n",
        "        if token not in STOPWORDS: #and if len(token)>3\n",
        "            result.append(lemmatize_stemming(token))\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-9E_d-CScUu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lemmatized_data = comments['comment'].apply(preprocess).values.tolist()\n",
        "texts_toxicity = comments['toxicity'].values.tolist()\n",
        "# Create Dictionary\n",
        "id2word = corpora.Dictionary(lemmatized_data)\n",
        "\n",
        "# Create Corpus\n",
        "texts= lemmatized_data\n",
        "\n",
        "# Term Document Frequency\n",
        "corpus = [id2word.doc2bow(text) for text in texts]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m8WfjCUnFVk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_topics=20\n",
        "wiki_lda = gensim.models.LdaMulticore(corpus=corpus, id2word=id2word, num_topics=num_topics, alpha='asymmetric', random_state= 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gmfe-S7qnQZl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "4202ed66-cadf-4707-e55e-adea22f83433"
      },
      "source": [
        "coherencemodel = CoherenceModel(model=wiki_lda, texts=texts, dictionary=id2word, coherence='c_v')\n",
        "print (coherencemodel.get_coherence())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5606252998138611\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcBFL4-0pcnq",
        "colab_type": "text"
      },
      "source": [
        "#Display topics and basic statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvW_RIgMi39Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fb071583-4652-4a11-ee58-66ea3c366a12"
      },
      "source": [
        "number_of_toxic = len([item for item in texts_toxicity if item==True])\n",
        "topics = {}\n",
        "topics_list = []\n",
        "topic_prob_list = []\n",
        "for text_id in range(len(corpus)):\n",
        "  this_comment_topics = wiki_lda[corpus[text_id]]\n",
        "  this_comment_topics.sort(key=lambda x:x[1])\n",
        "  t = this_comment_topics[-1]\n",
        "  topic_index = t[0]\n",
        "  topic_prob = t[1]\n",
        "  topics_list.append(topic_index)\n",
        "  topic_prob_list.append(topic_prob)\n",
        "  if topics.get(topic_index, None) is None:\n",
        "    topics[topic_index] = [text_id]\n",
        "  else:\n",
        "    topics[topic_index].append(text_id)\n",
        "for idx in range(num_topics):\n",
        "  print('Topic: {} \\nWords: {}'.format(idx, wiki_lda.print_topic(idx)))\n",
        "  print('%d documents  - %.3f of all the documnets' % (len(topics[idx]), len(topics[idx])/len(texts)))\n",
        "  positives = [v for v in topics[idx] if texts_toxicity[v] ]\n",
        "  print('%.2f percent toxic and %.2f of all the toxics' % (len(positives)/len(topics[idx]), len(positives)/number_of_toxic))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic: 0 \n",
            "Words: 0.025*\"know\" + 0.019*\"thank\" + 0.019*\"like\" + 0.015*\"think\" + 0.014*\"want\" + 0.013*\"look\" + 0.013*\"ll\" + 0.012*\"ve\" + 0.012*\"hi\" + 0.012*\"time\"\n",
            "31411 documents  - 0.197 of all the documnets\n",
            "0.18 percent toxic and 0.37 of all the toxics\n",
            "Topic: 1 \n",
            "Words: 0.012*\"time\" + 0.010*\"like\" + 0.009*\"peopl\" + 0.009*\"think\" + 0.007*\"year\" + 0.006*\"life\" + 0.006*\"day\" + 0.006*\"right\" + 0.006*\"drink\" + 0.006*\"million\"\n",
            "9306 documents  - 0.058 of all the documnets\n",
            "0.17 percent toxic and 0.10 of all the toxics\n",
            "Topic: 2 \n",
            "Words: 0.019*\"suck\" + 0.015*\"year\" + 0.010*\"citi\" + 0.009*\"new\" + 0.009*\"school\" + 0.008*\"cock\" + 0.008*\"old\" + 0.008*\"pussi\" + 0.007*\"dick\" + 0.007*\"women\"\n",
            "6282 documents  - 0.039 of all the documnets\n",
            "0.18 percent toxic and 0.07 of all the toxics\n",
            "Topic: 3 \n",
            "Words: 0.047*\"redirect\" + 0.039*\"talk\" + 0.036*\"utc\" + 0.035*\"categori\" + 0.031*\"film\" + 0.016*\"episod\" + 0.013*\"merg\" + 0.012*\"articl\" + 0.011*\"octob\" + 0.011*\"charact\"\n",
            "3175 documents  - 0.020 of all the documnets\n",
            "0.04 percent toxic and 0.01 of all the toxics\n",
            "Topic: 4 \n",
            "Words: 0.088*\"page\" + 0.080*\"wikipedia\" + 0.057*\"edit\" + 0.045*\"talk\" + 0.034*\"help\" + 0.034*\"articl\" + 0.030*\"thank\" + 0.022*\"question\" + 0.016*\"ask\" + 0.015*\"welcom\"\n",
            "10436 documents  - 0.065 of all the documnets\n",
            "0.04 percent toxic and 0.03 of all the toxics\n",
            "Topic: 5 \n",
            "Words: 0.085*\"sourc\" + 0.021*\"reliabl\" + 0.015*\"claim\" + 0.012*\"wikipedia\" + 0.012*\"cite\" + 0.012*\"inform\" + 0.011*\"refer\" + 0.011*\"fact\" + 0.010*\"publish\" + 0.009*\"research\"\n",
            "9420 documents  - 0.059 of all the documnets\n",
            "0.04 percent toxic and 0.03 of all the toxics\n",
            "Topic: 6 \n",
            "Words: 0.033*\"link\" + 0.029*\"list\" + 0.023*\"add\" + 0.023*\"page\" + 0.014*\"game\" + 0.013*\"inform\" + 0.011*\"articl\" + 0.010*\"date\" + 0.010*\"chang\" + 0.009*\"googl\"\n",
            "7857 documents  - 0.049 of all the documnets\n",
            "0.03 percent toxic and 0.01 of all the toxics\n",
            "Topic: 7 \n",
            "Words: 0.018*\"english\" + 0.017*\"languag\" + 0.016*\"peopl\" + 0.011*\"countri\" + 0.010*\"american\" + 0.009*\"nation\" + 0.008*\"term\" + 0.007*\"use\" + 0.007*\"word\" + 0.007*\"german\"\n",
            "7790 documents  - 0.049 of all the documnets\n",
            "0.06 percent toxic and 0.03 of all the toxics\n",
            "Topic: 8 \n",
            "Words: 0.045*\"kill\" + 0.039*\"live\" + 0.026*\"die\" + 0.022*\"eat\" + 0.019*\"jewish\" + 0.018*\"pro\" + 0.018*\"islam\" + 0.017*\"al\" + 0.017*\"jew\" + 0.017*\"israel\"\n",
            "927 documents  - 0.006 of all the documnets\n",
            "0.35 percent toxic and 0.02 of all the toxics\n",
            "Topic: 9 \n",
            "Words: 0.024*\"book\" + 0.023*\"god\" + 0.019*\"christian\" + 0.009*\"shall\" + 0.009*\"jesus\" + 0.008*\"presid\" + 0.008*\"william\" + 0.008*\"cast\" + 0.008*\"prime\" + 0.008*\"japanes\"\n",
            "1142 documents  - 0.007 of all the documnets\n",
            "0.13 percent toxic and 0.01 of all the toxics\n",
            "Topic: 10 \n",
            "Words: 0.099*\"delet\" + 0.048*\"articl\" + 0.045*\"imag\" + 0.033*\"wikipedia\" + 0.028*\"tag\" + 0.027*\"copyright\" + 0.025*\"page\" + 0.025*\"file\" + 0.024*\"notabl\" + 0.017*\"use\"\n",
            "6387 documents  - 0.040 of all the documnets\n",
            "0.02 percent toxic and 0.01 of all the toxics\n",
            "Topic: 11 \n",
            "Words: 0.018*\"univers\" + 0.016*\"th\" + 0.013*\"theori\" + 0.012*\"scienc\" + 0.012*\"law\" + 0.010*\"definit\" + 0.008*\"centuri\" + 0.008*\"capit\" + 0.008*\"student\" + 0.007*\"mean\"\n",
            "1912 documents  - 0.012 of all the documnets\n",
            "0.04 percent toxic and 0.00 of all the toxics\n",
            "Topic: 12 \n",
            "Words: 0.015*\"person\" + 0.013*\"editor\" + 0.012*\"admin\" + 0.011*\"attack\" + 0.011*\"say\" + 0.011*\"peopl\" + 0.010*\"wikipedia\" + 0.009*\"like\" + 0.008*\"user\" + 0.007*\"accus\"\n",
            "14047 documents  - 0.088 of all the documnets\n",
            "0.13 percent toxic and 0.12 of all the toxics\n",
            "Topic: 13 \n",
            "Words: 0.026*\"review\" + 0.024*\"discuss\" + 0.023*\"request\" + 0.023*\"vertic\" + 0.022*\"thank\" + 0.022*\"page\" + 0.020*\"templat\" + 0.018*\"comment\" + 0.018*\"talk\" + 0.018*\"nomin\"\n",
            "6467 documents  - 0.040 of all the documnets\n",
            "0.02 percent toxic and 0.01 of all the toxics\n",
            "Topic: 14 \n",
            "Words: 0.189*\"fuck\" + 0.072*\"shit\" + 0.056*\"ass\" + 0.050*\"stupid\" + 0.039*\"em\" + 0.036*\"moron\" + 0.033*\"bitch\" + 0.029*\"hate\" + 0.029*\"bastard\" + 0.028*\"cunt\"\n",
            "1316 documents  - 0.008 of all the documnets\n",
            "0.97 percent toxic and 0.08 of all the toxics\n",
            "Topic: 15 \n",
            "Words: 0.049*\"articl\" + 0.011*\"think\" + 0.011*\"section\" + 0.010*\"wp\" + 0.009*\"discuss\" + 0.009*\"editor\" + 0.008*\"refer\" + 0.008*\"point\" + 0.008*\"need\" + 0.007*\"chang\"\n",
            "30380 documents  - 0.190 of all the documnets\n",
            "0.02 percent toxic and 0.03 of all the toxics\n",
            "Topic: 16 \n",
            "Words: 0.040*\"team\" + 0.034*\"infobox\" + 0.028*\"award\" + 0.026*\"footbal\" + 0.024*\"win\" + 0.020*\"gay\" + 0.015*\"station\" + 0.014*\"match\" + 0.014*\"engin\" + 0.013*\"play\"\n",
            "485 documents  - 0.003 of all the documnets\n",
            "0.13 percent toxic and 0.00 of all the toxics\n",
            "Topic: 17 \n",
            "Words: 0.053*\"http\" + 0.044*\"com\" + 0.033*\"www\" + 0.031*\"org\" + 0.025*\"en\" + 0.018*\"state\" + 0.014*\"wiki\" + 0.014*\"unit\" + 0.011*\"compani\" + 0.008*\"html\"\n",
            "2857 documents  - 0.018 of all the documnets\n",
            "0.04 percent toxic and 0.01 of all the toxics\n",
            "Topic: 18 \n",
            "Words: 0.120*\"edit\" + 0.096*\"block\" + 0.037*\"vandal\" + 0.030*\"user\" + 0.029*\"account\" + 0.027*\"stop\" + 0.026*\"ip\" + 0.023*\"page\" + 0.022*\"war\" + 0.021*\"revert\"\n",
            "6738 documents  - 0.042 of all the documnets\n",
            "0.08 percent toxic and 0.04 of all the toxics\n",
            "Topic: 19 \n",
            "Words: 0.130*\"style\" + 0.096*\"px\" + 0.069*\"align\" + 0.060*\"color\" + 0.052*\"background\" + 0.051*\"pad\" + 0.044*\"middl\" + 0.038*\"border\" + 0.033*\"solid\" + 0.023*\"size\"\n",
            "1351 documents  - 0.008 of all the documnets\n",
            "0.06 percent toxic and 0.01 of all the toxics\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g11QRLt4pns5",
        "colab_type": "text"
      },
      "source": [
        "#Write the dataset with assigned topics and probabilities to a csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7cJ_qTHxnv7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "comments['wiki_topic'] = topics_list\n",
        "comments['wiki_topic_prob'] = topic_prob_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhqCx4UjF9HS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "comments.to_csv('wiki_lda_topics_lda_probabilities.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nd4LHiEAzOc_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "outputId": "3b05d5f8-5c88-41cd-ec34-d26846ba3d35"
      },
      "source": [
        "comments.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>year</th>\n",
              "      <th>logged_in</th>\n",
              "      <th>ns</th>\n",
              "      <th>sample</th>\n",
              "      <th>split</th>\n",
              "      <th>toxicity</th>\n",
              "      <th>wiki_topic</th>\n",
              "      <th>wiki_topic_prob</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rev_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2232.0</th>\n",
              "      <td>this   one can make an analogy in mathematical...</td>\n",
              "      <td>2002</td>\n",
              "      <td>True</td>\n",
              "      <td>article</td>\n",
              "      <td>random</td>\n",
              "      <td>train</td>\n",
              "      <td>False</td>\n",
              "      <td>15</td>\n",
              "      <td>0.641840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4216.0</th>\n",
              "      <td>clarification for you   and zundark s righ...</td>\n",
              "      <td>2002</td>\n",
              "      <td>True</td>\n",
              "      <td>user</td>\n",
              "      <td>random</td>\n",
              "      <td>train</td>\n",
              "      <td>False</td>\n",
              "      <td>15</td>\n",
              "      <td>0.299566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8953.0</th>\n",
              "      <td>elected or electoral  jhk</td>\n",
              "      <td>2002</td>\n",
              "      <td>False</td>\n",
              "      <td>article</td>\n",
              "      <td>random</td>\n",
              "      <td>test</td>\n",
              "      <td>False</td>\n",
              "      <td>13</td>\n",
              "      <td>0.677198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26547.0</th>\n",
              "      <td>this is such a fun entry    devotchka  i once...</td>\n",
              "      <td>2002</td>\n",
              "      <td>True</td>\n",
              "      <td>article</td>\n",
              "      <td>random</td>\n",
              "      <td>train</td>\n",
              "      <td>False</td>\n",
              "      <td>7</td>\n",
              "      <td>0.314508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28959.0</th>\n",
              "      <td>please relate the ozone hole to increases in c...</td>\n",
              "      <td>2002</td>\n",
              "      <td>True</td>\n",
              "      <td>article</td>\n",
              "      <td>random</td>\n",
              "      <td>test</td>\n",
              "      <td>False</td>\n",
              "      <td>15</td>\n",
              "      <td>0.348049</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   comment  ...  wiki_topic_prob\n",
              "rev_id                                                      ...                 \n",
              "2232.0   this   one can make an analogy in mathematical...  ...         0.641840\n",
              "4216.0       clarification for you   and zundark s righ...  ...         0.299566\n",
              "8953.0                           elected or electoral  jhk  ...         0.677198\n",
              "26547.0   this is such a fun entry    devotchka  i once...  ...         0.314508\n",
              "28959.0  please relate the ozone hole to increases in c...  ...         0.348049\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uh4_xb2Up1Vp",
        "colab_type": "text"
      },
      "source": [
        "#Topic Categories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOCdXVx9_eq_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "topic_categories={1:[0,1],\n",
        "                  2:[2,7,8,9,12,14,16],\n",
        "                  3:[3,4,5,6,10,11,13,15,17,18,19]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jschIUdABP7R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "6dba1135-ece3-42be-8295-ab4b60d8a384"
      },
      "source": [
        "len(comments[comments['wiki_topic'].isin(topic_categories[3]) ])/len(comments)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5446939619002292"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf4y2N1m_f9a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "745e4147-3901-43fc-f9ac-d118e594e1be"
      },
      "source": [
        "len(comments[comments['wiki_topic'].isin(topic_categories[3]) & comments['toxicity']])/len(comments[comments['toxicity']])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.17881786225751856"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUG1gBFpy__1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(comments[comments['split']=='train']['comment'].values.tolist()[topics[9][5]])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DH8jV6kFIJ3_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wiki_lda[corpus[topics[9][5]]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jix5imI4icrx",
        "colab_type": "text"
      },
      "source": [
        "#Reading Founta Dataset and labeling topics \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8OG1yZjeILd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Founta_df = pd.read_excel('Founta/hatespeech_text_label_vote.xlsx',header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vBZseJceWXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Founta_df.rename(columns={0: 'comment',1:'label',2:'vote'},inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lhLzi-KeZkM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Founta_df=Founta_df[Founta_df['label']!='spam']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_JwGncaeh5_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Founta_df['toxicity'] = Founta_df['label'].apply(lambda x: 0 if x=='normal' else 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jol0vUnEesN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lemmatized_data_Founta = Founta_df['comment'].apply(preprocess).values.tolist()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAtwdy0VgoGV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts_toxicity_Founta = Founta_df['toxicity'].values.tolist()\n",
        "\n",
        "\n",
        "# Term Document Frequency\n",
        "corpus_Founta = [id2word.doc2bow(text) for text in lemmatized_data_Founta]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtIWTCGpfCq8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 992
        },
        "outputId": "563b97d0-e37f-4169-e15a-08ca57b537c4"
      },
      "source": [
        "topic_prob_list = []\n",
        "topics_list = []\n",
        "topics_Founta = {}\n",
        "for text_id in range(len(corpus_Founta)):\n",
        "  this_comment_topics = wiki_lda[corpus_Founta[text_id]]  #### TODO : check sanity \n",
        "  this_comment_topics.sort(key=lambda x:x[1])\n",
        "  t = this_comment_topics[-1]\n",
        "  topic_index = t[0]\n",
        "  topic_prob = t[1]\n",
        "  topics_list.append(topic_index)\n",
        "  topic_prob_list.append(topic_prob)\n",
        "  if topics_Founta.get(topic_index, None) is None:\n",
        "    topics_Founta[topic_index] = [text_id]\n",
        "  else:\n",
        "    topics_Founta[topic_index].append(text_id)\n",
        "for idx in range(num_topics):\n",
        "  print('Topic: {} '.format(idx))\n",
        "  print('%d documents  - %.3f of all the documnets' % (len(topics_Founta[idx]), len(topics_Founta[idx])/len(lemmatized_data_Founta)))\n",
        "  toxic = [v for v in topics_Founta[idx] if texts_toxicity_Founta[v]==1 ]\n",
        "  print('%.2f percent toxic' % (len(toxic)/len(topics_Founta[idx])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic: 0 \n",
            "28363 documents  - 0.330 of all the documnets\n",
            "0.45 percent toxic\n",
            "Topic: 1 \n",
            "17557 documents  - 0.204 of all the documnets\n",
            "0.32 percent toxic\n",
            "Topic: 2 \n",
            "10698 documents  - 0.124 of all the documnets\n",
            "0.26 percent toxic\n",
            "Topic: 3 \n",
            "770 documents  - 0.009 of all the documnets\n",
            "0.34 percent toxic\n",
            "Topic: 4 \n",
            "1172 documents  - 0.014 of all the documnets\n",
            "0.18 percent toxic\n",
            "Topic: 5 \n",
            "1422 documents  - 0.017 of all the documnets\n",
            "0.20 percent toxic\n",
            "Topic: 6 \n",
            "3447 documents  - 0.040 of all the documnets\n",
            "0.20 percent toxic\n",
            "Topic: 7 \n",
            "2673 documents  - 0.031 of all the documnets\n",
            "0.30 percent toxic\n",
            "Topic: 8 \n",
            "883 documents  - 0.010 of all the documnets\n",
            "0.57 percent toxic\n",
            "Topic: 9 \n",
            "1368 documents  - 0.016 of all the documnets\n",
            "0.42 percent toxic\n",
            "Topic: 10 \n",
            "252 documents  - 0.003 of all the documnets\n",
            "0.27 percent toxic\n",
            "Topic: 11 \n",
            "1408 documents  - 0.016 of all the documnets\n",
            "0.25 percent toxic\n",
            "Topic: 12 \n",
            "5400 documents  - 0.063 of all the documnets\n",
            "0.41 percent toxic\n",
            "Topic: 13 \n",
            "1344 documents  - 0.016 of all the documnets\n",
            "0.22 percent toxic\n",
            "Topic: 14 \n",
            "3830 documents  - 0.045 of all the documnets\n",
            "0.98 percent toxic\n",
            "Topic: 15 \n",
            "2311 documents  - 0.027 of all the documnets\n",
            "0.11 percent toxic\n",
            "Topic: 16 \n",
            "853 documents  - 0.010 of all the documnets\n",
            "0.14 percent toxic\n",
            "Topic: 17 \n",
            "1866 documents  - 0.022 of all the documnets\n",
            "0.12 percent toxic\n",
            "Topic: 18 \n",
            "259 documents  - 0.003 of all the documnets\n",
            "0.42 percent toxic\n",
            "Topic: 19 \n",
            "90 documents  - 0.001 of all the documnets\n",
            "0.26 percent toxic\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYvvY0pZfkne",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Founta_df['wiki_topic'] = topics_list\n",
        "Founta_df['wiki_topic_prob'] = topic_prob_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydZMdECEfy9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Founta_df.to_csv('Founta_wiki_lda_topics_lda_probabilities.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYT8qPIZzv2L",
        "colab_type": "text"
      },
      "source": [
        "#Reading Waseem Dataset and Labeling Topics "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FN4ABJzdd4Qy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sexism = pd.read_json('Waseem/sexism.json',lines=True)\n",
        "racism = pd.read_json('Waseem/racism.json',lines=True)\n",
        "neither = pd.read_json('Waseem/neither.json',lines=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKnbFfUwo7o3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "frames = [sexism, racism,neither]\n",
        "waseem_df = pd.concat(frames).reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGqHm75aepuj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "waseem_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvJN7PLgOrOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import preprocessor as p\n",
        "\n",
        "waseem_df['comment'] = waseem_df['text'].apply(str).apply(p.clean).apply(lambda x:re.sub(r'[^A-Za-z0-9 ]+', ' ', x).lower())\n",
        "waseem_df['toxicity'] = waseem_df['Annotation'].apply(lambda x:False if x=='none' else True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-0dyNI-O3aW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lemmatized_data_waseem = waseem_df['comment'].apply(preprocess).values.tolist()\n",
        "texts_toxicity_waseem = waseem_df['Annotation'].values.tolist()\n",
        "\n",
        "\n",
        "# Term Document Frequency\n",
        "corpus_waseem = [id2word.doc2bow(text) for text in lemmatized_data_waseem]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH4EkHvhTHRo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#number_of_toxic_waseem = len([item for item in texts_toxicity_waseem if item ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMUiCfmvaFqa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "08c37d4c-ea63-4f80-f88e-5b6812ac7cd8"
      },
      "source": [
        "list(set(texts_toxicity_waseem))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sexism', 'racism', 'none']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwJGS5lfSR3Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 992
        },
        "outputId": "6416c5ee-a9cd-4265-fe18-ebfe9a7afc8e"
      },
      "source": [
        "topic_prob_list = []\n",
        "topics_list = []\n",
        "topics_waseem = {}\n",
        "for text_id in range(len(corpus_waseem)):\n",
        "  this_comment_topics = wiki_lda[corpus_waseem[text_id]]  #### TODO : check sanity \n",
        "  this_comment_topics.sort(key=lambda x:x[1])\n",
        "  t = this_comment_topics[-1]\n",
        "  topic_index = t[0]\n",
        "  topic_prob = t[1]\n",
        "  topics_list.append(topic_index)\n",
        "  topic_prob_list.append(topic_prob)\n",
        "  if topics_waseem.get(topic_index, None) is None:\n",
        "    topics_waseem[topic_index] = [text_id]\n",
        "  else:\n",
        "    topics_waseem[topic_index].append(text_id)\n",
        "for idx in range(num_topics):\n",
        "  print('Topic: {} '.format(idx))\n",
        "  print('%d documents  - %.3f of all the documnets' % (len(topics_waseem[idx]), len(topics_waseem[idx])/len(lemmatized_data_waseem)))\n",
        "  racism = [v for v in topics_waseem[idx] if texts_toxicity_waseem[v]=='racism' ]\n",
        "  sexism = [v for v in topics_waseem[idx] if texts_toxicity_waseem[v]=='sexism' ]\n",
        "  print('%.2f percent racist and %.2f percent sexist' % (len(racism)/len(topics_waseem[idx]), len(sexism)/len(topics_waseem[idx])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic: 0 \n",
            "5618 documents  - 0.332 of all the documnets\n",
            "0.03 percent racist and 0.20 percent sexist\n",
            "Topic: 1 \n",
            "2985 documents  - 0.177 of all the documnets\n",
            "0.10 percent racist and 0.20 percent sexist\n",
            "Topic: 2 \n",
            "1682 documents  - 0.099 of all the documnets\n",
            "0.11 percent racist and 0.35 percent sexist\n",
            "Topic: 3 \n",
            "104 documents  - 0.006 of all the documnets\n",
            "0.01 percent racist and 0.31 percent sexist\n",
            "Topic: 4 \n",
            "291 documents  - 0.017 of all the documnets\n",
            "0.05 percent racist and 0.26 percent sexist\n",
            "Topic: 5 \n",
            "411 documents  - 0.024 of all the documnets\n",
            "0.11 percent racist and 0.18 percent sexist\n",
            "Topic: 6 \n",
            "415 documents  - 0.025 of all the documnets\n",
            "0.03 percent racist and 0.18 percent sexist\n",
            "Topic: 7 \n",
            "641 documents  - 0.038 of all the documnets\n",
            "0.26 percent racist and 0.13 percent sexist\n",
            "Topic: 8 \n",
            "1060 documents  - 0.063 of all the documnets\n",
            "0.61 percent racist and 0.02 percent sexist\n",
            "Topic: 9 \n",
            "257 documents  - 0.015 of all the documnets\n",
            "0.29 percent racist and 0.26 percent sexist\n",
            "Topic: 10 \n",
            "68 documents  - 0.004 of all the documnets\n",
            "0.04 percent racist and 0.13 percent sexist\n",
            "Topic: 11 \n",
            "328 documents  - 0.019 of all the documnets\n",
            "0.20 percent racist and 0.19 percent sexist\n",
            "Topic: 12 \n",
            "1665 documents  - 0.098 of all the documnets\n",
            "0.14 percent racist and 0.20 percent sexist\n",
            "Topic: 13 \n",
            "215 documents  - 0.013 of all the documnets\n",
            "0.06 percent racist and 0.25 percent sexist\n",
            "Topic: 14 \n",
            "146 documents  - 0.009 of all the documnets\n",
            "0.03 percent racist and 0.36 percent sexist\n",
            "Topic: 15 \n",
            "584 documents  - 0.035 of all the documnets\n",
            "0.07 percent racist and 0.21 percent sexist\n",
            "Topic: 16 \n",
            "183 documents  - 0.011 of all the documnets\n",
            "0.03 percent racist and 0.16 percent sexist\n",
            "Topic: 17 \n",
            "150 documents  - 0.009 of all the documnets\n",
            "0.08 percent racist and 0.07 percent sexist\n",
            "Topic: 18 \n",
            "88 documents  - 0.005 of all the documnets\n",
            "0.03 percent racist and 0.14 percent sexist\n",
            "Topic: 19 \n",
            "16 documents  - 0.001 of all the documnets\n",
            "0.00 percent racist and 0.06 percent sexist\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dacNtAeBgVo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "waseem_df['wiki_topic'] = topics_list\n",
        "waseem_df['wiki_topic_prob'] = topic_prob_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0wg7Tb7Bk1B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "waseem_df.sample(n = 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLKkWwe_NQui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "waseem_df_to_save = waseem_df[['index', 'Annotation', 'comment', 'toxicity', 'wiki_topic', 'wiki_topic_prob']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw6HaRj7N4sA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "97a5c31a-a648-4a47-ec97-fd106d850d64"
      },
      "source": [
        "waseem_df_to_save.sample(n = 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Annotation</th>\n",
              "      <th>comment</th>\n",
              "      <th>toxicity</th>\n",
              "      <th>wiki_topic</th>\n",
              "      <th>wiki_topic_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>1337</td>\n",
              "      <td>sexism</td>\n",
              "      <td>appears to refer to the idea that denial of vi...</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "      <td>0.518908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11624</th>\n",
              "      <td>6218</td>\n",
              "      <td>none</td>\n",
              "      <td>aw  gamergate harassment squad  did i say some...</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0.425006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15860</th>\n",
              "      <td>10454</td>\n",
              "      <td>none</td>\n",
              "      <td>their report is the very definition of cherry ...</td>\n",
              "      <td>False</td>\n",
              "      <td>5</td>\n",
              "      <td>0.347926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4022</th>\n",
              "      <td>592</td>\n",
              "      <td>racism</td>\n",
              "      <td>so the only way the problems of islam can be f...</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>0.432325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9037</th>\n",
              "      <td>3631</td>\n",
              "      <td>none</td>\n",
              "      <td>host colin fassnidge in his element at</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>0.582365</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       index Annotation  ... wiki_topic  wiki_topic_prob\n",
              "1337    1337     sexism  ...          5         0.518908\n",
              "11624   6218       none  ...          0         0.425006\n",
              "15860  10454       none  ...          5         0.347926\n",
              "4022     592     racism  ...          0         0.432325\n",
              "9037    3631       none  ...          1         0.582365\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1nO-iuaBxaC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "waseem_df_to_save.to_csv('waseem_wiki_lda_topics_lda_probabilities.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQTTsGcpWIQt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}